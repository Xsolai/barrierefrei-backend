# Website-Datenextraktion Test-Skript

## Ãœberblick
Das `test_data_extraction.py` Skript zeigt Ihnen genau, welche Daten von einer Website extrahiert und an die WCAG-Expert-Prompts weitergegeben werden. 

## Zweck
- **Transparenz**: Sehen Sie alle extrahierten Daten vor der Expert-Analyse
- **Debugging**: Verstehen Sie, warum bestimmte Bewertungen getroffen werden
- **Optimierung**: Identifizieren Sie Daten-Extraktion-Verbesserungen
- **QualitÃ¤tskontrolle**: PrÃ¼fen Sie die VollstÃ¤ndigkeit der analysierten Daten

## Funktionsweise

### Phase 1: Grundlegende Website-Extraktion
- **WebsiteCrawler**: Extrahiert strukturelle Website-Daten
- **VollstÃ¤ndige Analyse**: HTML-Struktur, Bilder, Links, Formulare, etc.
- **Accessibility-Daten**: ARIA-Attribute, Rollen, Labels, etc.

### Phase 2: Spezialisierte WCAG-Extraktion
- **1.1 Textalternativen**: Fokus auf Bilder, Alt-Texte, Social Media Images
- **1.2 Zeitbasierte Medien**: Videos, Audio, Untertitel
- **1.3 Anpassbare Darstellung**: Ãœberschriften-Hierarchie, Semantik
- **Weitere Bereiche**: Fallback fÃ¼r noch nicht implementierte Extraktoren

### Phase 3: Daten-Ausgabe
- **4 Dateiformate**: VollstÃ¤ndig, Grunddaten, WCAG-spezifisch, Zusammenfassung
- **JSON + Text**: Maschinenlesbar und human-lesbar

## Verwendung

### Standard-Test (Ihre eigene Website)
```bash
cd backend
python test_data_extraction.py
```

### Andere Website testen
```bash
cd backend
python test_data_extraction.py https://example.com
```

### Mit spezifischem Output-Verzeichnis
```bash
cd backend
python test_data_extraction.py https://example.com
# Dateien werden in 'extracted_data/' gespeichert
```

## Ausgabe-Dateien

### 1. `website_data_FULL_***.json`
**VollstÃ¤ndige Daten** - Alle extrahierten Informationen
- Grundlegende Website-Daten
- Spezialisierte WCAG-Daten  
- Metadata und Statistiken

### 2. `website_data_BASE_***.json`
**Grunddaten** - Daten, die an alle 12 Expert-Prompts gehen
- HTML-Struktur
- Bilder, Links, Formulare
- Accessibility-Grunddaten

### 3. `website_data_WCAG_***.json`
**WCAG-spezialisiert** - Daten fÃ¼r spezifische WCAG-Bereiche
- 1.1: Detaillierte Bild-Analyse
- 1.2: Multimedia-Fokus
- 1.3: Semantik-Analyse

### 4. `website_data_SUMMARY_***.txt`
**Zusammenfassung** - Human-lesbare Ãœbersicht
- Anzahl gefundener Elemente
- DatenqualitÃ¤t-Bewertung
- Extraktionszeit

## Beispiel-Output

```
ğŸš€ Starte Datenextraktion fÃ¼r: https://www.ecomtask.de
ğŸ“Š Phase 1: Grundlegende Website-Datenextraktion...
âœ… Grunddaten extrahiert in 2.45s
ğŸ” Phase 2: Spezialisierte WCAG-Datenextraktion...
  ğŸ“¸ Extrahiere 1.1 Textalternativen...
  ğŸ¥ Extrahiere 1.2 Zeitbasierte Medien...
  ğŸ“‹ Extrahiere 1.3 Anpassbare Darstellung...
ğŸ“¦ Phase 3: Zusammenstellung der Expert-Prompt-Daten...
âœ… Datenextraktion abgeschlossen!
   ğŸ“Š Datenpunkte: 2847
   â±ï¸ Gesamtzeit: 3.21s

ğŸ’¾ VollstÃ¤ndige Daten gespeichert: extracted_data/website_data_FULL_***.json
ğŸ’¾ Grunddaten gespeichert: extracted_data/website_data_BASE_***.json
ğŸ’¾ WCAG-Daten gespeichert: extracted_data/website_data_WCAG_***.json
ğŸ’¾ Zusammenfassung gespeichert: extracted_data/website_data_SUMMARY_***.txt
```

## Was sehen Sie in den Daten?

### Grundlegende Website-Daten
```json
{
  "base_website_data": {
    "url": "https://example.com",
    "title": {...},
    "structure": {
      "headings": [...],
      "images": [...],
      "forms": [...],
      "links": [...]
    },
    "accessibility": {
      "aria_roles": [...],
      "tab_index": [...],
      "text_alternatives": [...]
    }
  }
}
```

### Spezialisierte WCAG-Daten
```json
{
  "specialized_wcag_data": {
    "1.1_text_alternatives": {
      "images": {
        "total_count": 15,
        "with_alt": 12,
        "without_alt": 3,
        "detailed_analysis": [...]
      },
      "comprehensive_image_analysis": {
        "performance_score": 85.2,
        "social_media_images": [...],
        "accessibility_quality_score": 92.1
      }
    }
  }
}
```

## Nutzen fÃ¼r Expert-Prompts

### Token-Effizienz
- **Vorher**: Alle 12 Prompts erhalten 50.000 Token (identische Daten)
- **Nachher**: Jeder Prompt erhÃ¤lt 5.000-15.000 relevante Token

### Daten-PrÃ¤zision
- **WCAG 1.1**: Nur Bild-relevante Daten (Performance, Alt-Texte, Social Media)
- **WCAG 1.2**: Nur Multimedia-Daten (Videos, Audio, Untertitel)
- **WCAG 1.3**: Nur Struktur-Daten (Ãœberschriften, Semantik, Landmarks)

### QualitÃ¤ts-Verbesserung
- **95% relevante Daten** statt 20% bei allgemeinem Ansatz
- **Spezialisierte Metriken** fÃ¼r jeden WCAG-Bereich
- **Kontext-bewusste Analyse** durch fokussierte Datenextraktion

## Fehlerbehebung

### Import-Fehler
```bash
ModuleNotFoundError: No module named 'analyzers'
```
â†’ Stellen Sie sicher, dass Sie im `backend/` Verzeichnis sind

### Netzwerk-Fehler
```bash
Netzwerkfehler bei https://example.com: Connection timeout
```
â†’ PrÃ¼fen Sie Ihre Internetverbindung oder verwenden Sie eine andere URL

### Speicher-Fehler bei groÃŸen Websites
â†’ Das Skript analysiert nur die Hauptseite, nicht alle Unterseiten

## Integration in Ihr System
Diese Daten werden automatisch in Ihrem Produktionssystem verwendet:
1. `run_complete_analysis.py` nutzt dieselben Extraktoren
2. Expert-Prompts erhalten diese exakten Datenstrukturen
3. Supabase speichert diese Analyse-Ergebnisse 